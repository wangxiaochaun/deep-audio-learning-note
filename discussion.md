## "Envorinmental Sound Classification using Deep Learning"的复现报告

>###### 说明(#说明)|实验结果(#实验结果)|讨论(#讨论)|下一步工作(#下一步工作)

### 说明

复现的工作是[github上audio-classification](https://github.com/mtobeiyf/audio-classification)。因为这个project的源码比较清楚，所以复现难度几乎为0. 所做的贡献：改写了数据集读取部分，因为原始代码是为esc-10工作的，而esc现在只有esc-50数据集了。

关于n折交叉验证这块，目前有待商榷：

esc-50数据集自己将2000条音频分成了5个fold；每个fold里400条，覆盖了全部50个类，而且确保同一场景不同时间段的音频只在一个fold中出现，避免数据污染。在做n-fold cross validation的时候，esc-50自己给出的baseline数据是分别在各个fold中训练和测试（split_and_test），然后平均5个fold的结果。我个人觉得这么做可能导致每个fold的样本过少，尤其是后来训练DNN和CNN的时候，过拟合非常严重。按照我个人理解，仿照cv的做法，对传统ML方法，如核方法，可以任选4个folds做训练集，剩余一个fold做测试集；对DL方法，把fold5当做测试集，然后对剩余4个folds做4折交叉。实际实验中，对DL方法我并没有做4折交叉，而是做了5折交叉，所以严格说，DL方法的结果是在验证集上而不是测试集上的。另外可以看到DL方法在训练集上近乎完美，但是在测试集上表现平平，判断属于过拟合。

### 实验结果

>###### SVM(#SVM)|NN(#NN)|CNN(#CNN)

#### SVM

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold[<sup>[1]</sup>](#ref_1)|0.2562|0.4062|0.2812|0.3250|0.2812|0.3100|
|whole folds[<sup>[2]</sup>](#ref_2)|0.3625|0.3400|0.3550|0.3675|0.3275|0.3505|

<font size=2><div id="ref_1"></div>
[1] 对每个fold内部，按照0.4的比例切分train和test
<font size=2><div id="ref_2"></div>
[1] 对所有fold，选取80%为train，剩余20%为test

#### NN

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3750|0.4812|0.4312|0.4312|0.3437|0.4125|
|whole folds|0.4187|0.4937|0.4312|0.4875|0.3000|0.4263|

#### CNN

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3750|0.4687|0.4812|0.3937|0.3812|0.4200|
|whole folds|0.4187|0.4937|0.4312|0.4875|0.3000|0.4263|

### 讨论

可以看到，test性能依次上升，但是还差很多。另外inner fold方法效果差于whole folds方法。另外，NN和CNN方法在train的过程中，**可能**出现过拟合（train accuracy接近1，但是test accuracy很低）

那么是不是可以认为模型拟合能力不足呢？可以尝试更深的网络？

- 在cnn模型中添加了一组卷积层(maxpooling-Conv255-Conv256)：性能下降

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3125|0.4000|0.4187|0.4000|0.3249|0.3712|