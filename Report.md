# 语音识别实验报告

>### [摘要](#摘要)|[说明](#说明)|[实验结果](#实验结果)|[讨论](#讨论)|[下一步工作](#下一步工作)

### 摘要

特征提取这里主要使用了MFCC、Mel声谱图、Contrast声谱图和Toznet特征等。分类方法主要使用了SVM，NN，CNN以及迁移学习网络SoundNet。


### 说明

SVM,NN和CNN复现的基础是[github上audio-classification](https://github.com/mtobeiyf/audio-classification)。SoundNet这块采用的是代码<sup>[[paper](https://github.com/camila-ud/SoundNet-keras)]</sup>。论文原始代码是Torch做的。复现是Keras（Tensorflow bankend）做的。

关于n折交叉验证这块，目前有待商榷：

esc-50数据集自己将2000条音频分成了5个fold；每个fold里400条，覆盖了全部50个类，而且确保同一场景不同时间段的音频只在一个fold中出现，避免数据污染。在做n-fold cross validation的时候，esc-50自己给出的baseline数据是分别在各个fold中训练和测试（split_and_test），然后平均5个fold的结果。我个人觉得这么做可能导致每个fold的样本过少，尤其是后来训练DNN和CNN的时候，过拟合非常严重。按照我个人理解，仿照cv的做法，对传统ML方法，如核方法，可以任选4个folds做训练集，剩余一个fold做测试集；对DL方法，把fold5当做测试集，然后对剩余4个folds做4折交叉。实际实验中，对DL方法我并没有做4折交叉，而是做了5折交叉，所以严格说，DL方法的结果是在验证集上而不是测试集上的。另外可以看到DL方法在训练集上近乎完美，但是在测试集上表现平平，判断属于过拟合。

### 实验结果

实验结果如下所示。我们以MFCC、Mel声谱图、Contrast声谱图和Toznet特征作为输入，使用不同的分类方法，在ESC-50上进行了测试。

>##### [SVM](#SVM)|[NN](#NN)|[CNN](#CNN)|[SoundNet](#SoundNet)

#### SVM

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold[<sup>[1]</sup>](#ref_1)|0.2562|0.4062|0.2812|0.3250|0.2812|0.3100|
|whole folds[<sup>[2]</sup>](#ref_2)|0.3625|0.3400|0.3550|0.3675|0.3275|0.3505|

<font size=2><div id="ref_1"></div>
[1] 对每个fold内部，按照0.4的比例切分train和test
<font size=2><div id="ref_2"></div>
[1] 对所有fold，选取80%为train，剩余20%为test

#### NN

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3750|0.4812|0.4312|0.4312|0.3437|0.4125|
|whole folds|0.4187|0.4937|0.4312|0.4875|0.3000|0.4263|

#### CNN

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3750|0.4687|0.4812|0.3937|0.3812|0.4200|
|whole folds|0.4187|0.4937|0.4312|0.4875|0.3000|0.4263|

#### SoundNet

SoundNet网络结果如图所示:

![img](media\\sound.jpeg)

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.5000|0.6625|0.7375|0.6875|0.5625|0.6300|
|whole folds|0.6150|0.9775|0.9975|1.0000|1.0000|0.9180|


### 讨论

可以看到，在ESC-50上，SoundNet表现最好。其余方法性能和SoundNet相比差异较为明显。最为关键的是，SoundNet实际上是一个迁移学习网络，是从ImageNet等图像识别数据集上训练并迁移到音频上的。这印证了一个观点：即语音信号相对图像信号来说，复杂度要低很多。另外inner fold方法效果差于whole folds方法。这个主要原因应该是数据集容量问题，inner fold数据集容量较小，训练过程很容易出现过拟合。

为验证数据集容量导致过拟合，我们尝试增加卷积层组，在cnn模型中添加了一组卷积层(maxpooling-Conv255-Conv256)。在ESC-50上性能下降：

|交叉验证模式|1|2|3|4|5|Avg.|
|:--|:--|:--|:--|:--|:--|:--|
|inner fold|0.3125|0.4000|0.4187|0.4000|0.3249|0.3712|


实验结果验证了我们的假设，即网络出现了过拟合。

### 下一步工作

SoudNet在ESC-50上达到了92%的识别准确率，但是仍有提升空间。但是，考虑到数据集样本数有限，简单通过增加网络深度不能解决这一问题。因此，考虑从两个方面解决这一问题：一方面，进一步利用迁移学习，从其他数据集中获取有效的先验；一方面，对数据集中的音频文件，考虑采用分帧的方式将其看作时间序列，采用RNN/LSTM的方法取代传统的音频特征表示方式，增加可训练参数，提高模型的拟合能力。
